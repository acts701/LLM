{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNAV9QkZNVERnupG183De1h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acts701/LLM/blob/main/250303_makeSummary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "id": "5NYMg2llJBSE",
        "outputId": "2a990e5b-778d-4671-b59b-690bd191e422",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv5UbuG0IvqL",
        "outputId": "fd43bfa3-9b01-4a31-b45a-d9660e5cc04a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from google.colab import drive, userdata\n",
        "from docx import Document\n",
        "\n",
        "# ✅ Google Drive 마운트\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ✅ OpenAI API 키 설정\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "if api_key is None:\n",
        "    raise ValueError(\"API 키를 찾을 수 없습니다. userdata에 API 키를 저장했는지 확인하세요.\")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "client = OpenAI()\n",
        "\n",
        "# ✅ 경로 설정\n",
        "questions_dir = \"/content/drive/MyDrive/LLM/Data/QnA/QuestionsSplitted\"\n",
        "sources_dir = \"/content/drive/MyDrive/LLM/Data/voiceToText/clovaPaid\"\n",
        "summary_dir = \"/content/drive/MyDrive/LLM/Data/Summary\"\n",
        "file_batch_dir = \"/content/drive/MyDrive/LLM/Data/fileBatchIDs\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Summary 폴더 없으면 생성\n",
        "os.makedirs(summary_dir, exist_ok=True)\n",
        "os.makedirs(file_batch_dir, exist_ok=True)\n",
        "# ✅ 폴더 내 파일 리스트 가져오기\n",
        "json_files = [f for f in os.listdir(questions_dir) if f.endswith('.json')]"
      ],
      "metadata": {
        "id": "neuU2F9fI3Wl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_file(txt_file_path):\n",
        "    attach_file = client.files.create(file=open(txt_file_path, \"rb\"), purpose=\"assistants\")\n",
        "    return attach_file.id"
      ],
      "metadata": {
        "id": "k0V9NMtZVqiZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "        instructions=\"첨부 txt와 json 파일을 이용해서 txt를 요약해줘\",\n",
        "        name=\"이사야 전문가\",\n",
        "        tools=[{\"type\": \"file_search\"}],\n",
        "        # model=\"gpt-3.5-turbo-0125\",\n",
        "        model=\"gpt-4o-mini-2024-07-18\"\n",
        "    )"
      ],
      "metadata": {
        "id": "tqrt_i57V9j2"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for json_file in json_files:\n",
        "    if \"사 1장 1-9 공부\" not in json_file:\n",
        "        continue\n",
        "\n",
        "    base_name = os.path.splitext(json_file)[0]\n",
        "    json_file_path = os.path.join(questions_dir, json_file)\n",
        "    txt_file_path = os.path.join(sources_dir, base_name + \".txt\")\n",
        "\n",
        "    if not os.path.exists(txt_file_path):\n",
        "        print(f\"⚠️ 해당하는 TXT 파일이 없습니다: {txt_file_path}\")\n",
        "        continue\n",
        "\n",
        "    # Create a vector store caled \"Financial Statements\"\n",
        "    vector_store = client.beta.vector_stores.create(name=\"Isaiah Expert\")\n",
        "\n",
        "    # Ready the files for upload to OpenAI\n",
        "    file_paths = [txt_file_path]\n",
        "    file_streams = [open(path, \"rb\") for path in file_paths]\n",
        "\n",
        "    # Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
        "    # and poll the status of the file batch for completion.\n",
        "    file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
        "        vector_store_id=vector_store.id, files=file_streams\n",
        "    )\n",
        "\n",
        "    # You can print the status and the file counts of the batch to see the result of this operation.\n",
        "    print(file_batch.status)\n",
        "    print(file_batch.file_counts)\n",
        "\n",
        "    assistant = client.beta.assistants.update(\n",
        "        assistant_id=assistant.id,\n",
        "        tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
        "    )\n",
        "\n",
        "    # Upload the user provided file to OpenAI\n",
        "    message_file = client.files.create(\n",
        "        file=open(json_file_path, \"rb\"), purpose=\"assistants\"\n",
        "    )\n",
        "\n",
        "    # Create a thread and attach the file to the message\n",
        "    thread = client.beta.threads.create(\n",
        "    messages=[\n",
        "        {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"첨부 파일을 이용해서 txt를 요약해줘\",\n",
        "        # Attach the new file to the message.\n",
        "        \"attachments\": [\n",
        "            { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
        "        ],\n",
        "        }\n",
        "    ]\n",
        "    )\n",
        "\n",
        "    # The thread now has a vector store with that file in its tool resources.\n",
        "    print(thread.tool_resources.file_search)\n",
        "\n",
        "    # Use the create and poll SDK helper to create a run and poll the status of\n",
        "    # the run until it's in a terminal state.\n",
        "\n",
        "    run = client.beta.threads.runs.create_and_poll(\n",
        "        thread_id=thread.id, assistant_id=assistant.id\n",
        "    )\n",
        "\n",
        "    messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
        "\n",
        "    message_content = messages[0].content[0].text\n",
        "    annotations = message_content.annotations\n",
        "    citations = []\n",
        "    for index, annotation in enumerate(annotations):\n",
        "        message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
        "        if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "            cited_file = client.files.retrieve(file_citation.file_id)\n",
        "            citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "    print(message_content.value)\n",
        "    print(\"\\n\".join(citations))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opxhRbfLOYjq",
        "outputId": "0d9fed59-55cc-45bd-8485-5dd8a772a874"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed\n",
            "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n",
            "ToolResourcesFileSearch(vector_store_ids=['vs_67c5bc4d407481919a5c606eed8f1cd4'])\n",
            "첨부된 파일의 내용은 이사야서에 대한 논의로, 유다와 예루살렘의 영적 상태를 분석하며 하나님과의 관계에 대한 경고와 회복의 가능성을 다루고 있습니다. 다음은 주요 내용을 요약한 것입니다.\n",
            "\n",
            "1. **하나님의 부르심과 경고**: 이사야는 하나님께서 유다와 예루살렘에 대해 경고하는 비전을 받습니다. 하나님은 자신의 백성이 자신을 거스르는 상황에 슬퍼하며 그들의 영적 상태를 진단합니다[0].\n",
            "\n",
            "2. **부패한 사회**: 유다 백성은 하나님과의 언약을 잊고 범죄하며 부패한 생활을 하고 있습니다. 이사야는 그들의 상태를 '병든 머리와 피곤한 마음'으로 표현하면서 그들이 처한 영적 황폐함을 강조합니다[1].\n",
            "\n",
            "3. **회복의 가능성**: 하나님은 상황이 완전히 무너져 가기 전에 돌아오기를 바라는 마음으로 이사야에게 메시지를 전달합니다. 초라한 남은 자들 속에서 여전히 소망이 존재함을 알리며, 그들을 통해 다시 회복할 수 있는 기회를 제공합니다[2][3].\n",
            "\n",
            "4. **하나님과의 관계의 회복**: 이사야는 백성이 하나님을 다시 찾고 그와의 관계를 회복해야 함을 강조합니다. 상황이 어렵고 불확실할 때일수록 하나님의 인도하심을 믿고 의지해야 한다고 경고합니다[4].\n",
            "\n",
            "5. **현재의 교훈**: 이 메시지는 오늘날 신자들에게도 적용될 수 있으며, 자신들의 상태를 인식하고 하나님께 돌아가야 할 필요성을 일깨워줍니다. 그들은 매일의 삶에서 하나님의 말씀에 귀 기울여야 하며, 세상의 소음에 휩쓸리지 않도록 주의해야 합니다[5][6].\n",
            "\n",
            "이 사역은 이사야의 개인적 경험과 그가 이스라엘 백성에게 전달하고자 했던 하나님 메시지의 중요성을 강조합니다. 이를 통해 신앙인들은 단지 과거의 이야기가 아니라 현재의 우리에게도 관련이 있음을 느낄 수 있습니다.\n",
            "[0] 사 1장 1-9 공부.txt\n",
            "[1] 사 1장 1-9 공부.txt\n",
            "[2] 사 1장 1-9 공부.txt\n",
            "[3] 사 1장 1-9 공부.txt\n",
            "[4] 사 1장 1-9 공부.txt\n",
            "[5] 사 1장 1-9 공부.txt\n",
            "[6] 사 1장 1-9 공부.txt\n"
          ]
        }
      ]
    }
  ]
}